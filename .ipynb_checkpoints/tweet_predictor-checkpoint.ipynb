{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "MAX_WORDS = 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"trump_tweets_11_17.json\")\n",
    "replacement_dict = {\"Twitter for iPhone\": 1, \"Twitter for Android\": 0}\n",
    "df = df.replace(to_replace=replacement_dict)   # replace labels\n",
    "df = df[df.source.apply(lambda x: type(x) == int)]  # remove tweets from other sources\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD:tweet_predictor.ipynb
    "training = df.sample(frac=0.8, random_state=0)\n",
    "testing = df.drop(training.index)"
=======
    "tokenizer = Tokenizer(num_words=15000)\n",
    "tokenizer.fit_on_texts(df[\"text\"])\n",
    "sequences = tokenizer.texts_to_sequences(df[\"text\"])\n",
    "text_sequences = pad_sequences(sequences, maxlen=65)\n",
    "#df['tokenized_text'] = text_sequences"
>>>>>>> d86af5736c0f7810a4dfe84fa68099d699cb79f5:.ipynb_checkpoints/tweet_predictor-checkpoint.ipynb
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=15000)\n",
    "tokenizer.fit_on_texts(training[\"text\"])\n",
    "sequences = tokenizer.texts_to_sequences(training[\"text\"])\n",
    "text_sequences = pad_sequences(sequences, maxlen=65)\n",
    "dictionary = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:tweet_predictor.ipynb
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(65,), activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))"
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,    17,   107,  1045],\n",
       "       [    0,     0,     0, ...,    17,   107,  1045],\n",
       "       [    0,     0,     0, ...,     8,     9, 11283],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,    11,    61,   102],\n",
       "       [    0,     0,     0, ...,   492,    46,    41],\n",
       "       [    0,     0,     0, ...,  1737,     4,    61]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences"
>>>>>>> d86af5736c0f7810a4dfe84fa68099d699cb79f5:.ipynb_checkpoints/tweet_predictor-checkpoint.ipynb
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD:tweet_predictor.ipynb
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "  optimizer='adagrad',\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class weights for imbalanced dataset\n",
    "y_train = training[\"source\"]\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
=======
   "execution_count": null,
>>>>>>> d86af5736c0f7810a4dfe84fa68099d699cb79f5:.ipynb_checkpoints/tweet_predictor-checkpoint.ipynb
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13391 samples, validate on 1488 samples\n",
      "Epoch 1/5\n",
      "13391/13391 [==============================] - 1s 63us/step - loss: 3.7787 - acc: 0.7630 - val_loss: 3.7713 - val_acc: 0.7634\n",
      "Epoch 2/5\n",
      "13391/13391 [==============================] - 1s 62us/step - loss: 3.7787 - acc: 0.7630 - val_loss: 3.7713 - val_acc: 0.7634\n",
      "Epoch 3/5\n",
      "13391/13391 [==============================] - 1s 64us/step - loss: 3.7787 - acc: 0.7630 - val_loss: 3.7713 - val_acc: 0.7634\n",
      "Epoch 4/5\n",
      "13391/13391 [==============================] - 1s 67us/step - loss: 3.7787 - acc: 0.7630 - val_loss: 3.7713 - val_acc: 0.7634\n",
      "Epoch 5/5\n",
      "13391/13391 [==============================] - 1s 63us/step - loss: 3.7787 - acc: 0.7630 - val_loss: 3.7713 - val_acc: 0.7634\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9103265630>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(text_sequences, training[\"source\"],\n",
    "  batch_size=64,\n",
    "  epochs=5,\n",
    "  verbose=1,\n",
    "  validation_split=0.1,\n",
    "  shuffle=True, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
