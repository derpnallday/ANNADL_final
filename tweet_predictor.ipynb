{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "MAX_WORDS = 15000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPARE LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"trump_tweets_11_17.json\")\n",
    "replacement_dict = {\"Twitter for iPhone\": 1, \"Twitter for Android\": 0}\n",
    "df = df.replace(to_replace=replacement_dict)   # replace labels\n",
    "df = df[df.source.apply(lambda x: type(x) == int)]  # remove tweets from other sources\n",
    "df = df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = df.sample(frac=0.8, random_state=0)\n",
    "testing = df.drop(training.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=15000)\n",
    "tokenizer.fit_on_texts(training[\"text\"])\n",
    "sequences = tokenizer.texts_to_sequences(training[\"text\"])\n",
    "text_sequences = pad_sequences(sequences, maxlen=65)\n",
    "dictionary = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(65,), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='sigmoid'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13391 samples, validate on 1488 samples\n",
      "Epoch 1/5\n",
      "13391/13391 [==============================] - 4s 326us/step - loss: 0.2378 - accuracy: 0.7622 - val_loss: 0.2392 - val_accuracy: 0.7608\n",
      "Epoch 2/5\n",
      "13391/13391 [==============================] - 3s 253us/step - loss: 0.2378 - accuracy: 0.7622 - val_loss: 0.2392 - val_accuracy: 0.7608\n",
      "Epoch 3/5\n",
      "13391/13391 [==============================] - 3s 245us/step - loss: 0.2378 - accuracy: 0.7622 - val_loss: 0.2392 - val_accuracy: 0.7608\n",
      "Epoch 4/5\n",
      "13391/13391 [==============================] - 3s 222us/step - loss: 0.2378 - accuracy: 0.7622 - val_loss: 0.2392 - val_accuracy: 0.7608\n",
      "Epoch 5/5\n",
      "13391/13391 [==============================] - 3s 236us/step - loss: 0.2378 - accuracy: 0.7622 - val_loss: 0.2392 - val_accuracy: 0.7608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f73de779ed0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(text_sequences, training[\"source\"],\n",
    "  batch_size=32,\n",
    "  epochs=5,\n",
    "  verbose=1,\n",
    "  validation_split=0.1,\n",
    "  shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 512)               33792     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 165,634\n",
      "Trainable params: 165,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
